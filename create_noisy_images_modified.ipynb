{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e41fa9dc",
   "metadata": {
    "id": "e41fa9dc"
   },
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "hntu3HU412Zr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hntu3HU412Zr",
    "outputId": "8cc957d2-d82b-4c6c-ead9-a53abd6c8d14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'CS2529_Project' already exists and is not an empty directory.\n",
      "mv: cannot stat 'CS2529_Project/*': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "*Uncomment if running on colab* \n",
    "Set Runtime -> Change runtime type -> Under Hardware Accelerator select GPU in Google Colab \n",
    "\"\"\"\n",
    "# !git clone https://github.com/b23shen/CS2529_Project.git\n",
    "# !mv CS2529_Project/* ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a092fb4b",
   "metadata": {
    "id": "a092fb4b"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.fft import fft2, ifft2\n",
    "import numpy as np\n",
    "from utils.create_noisy_images_utils import BSDS300Dataset\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import Compose, ToTensor, Lambda\n",
    "from utils.models import Unet\n",
    "import statistics\n",
    "import skimage.io\n",
    "\n",
    "from skimage.filters import gaussian\n",
    "from scipy.ndimage import median_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5361aae4",
   "metadata": {
    "id": "5361aae4"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6deb6cf2",
   "metadata": {
    "id": "6deb6cf2"
   },
   "outputs": [],
   "source": [
    "class BlurredBSDS300Dataset(BSDS300Dataset):\n",
    "    def __init__(self, root='./data/BSDS300', patch_size=32, split='train', use_patches=True,\n",
    "                 kernel_size=7, sigma=2, return_kernel=True):\n",
    "        super(BlurredBSDS300Dataset, self).__init__(root, patch_size, split)\n",
    "\n",
    "        # trim images to even size\n",
    "        self.images = self.images[..., :-1, :-1]\n",
    "        self.kernel_size = kernel_size\n",
    "        self.return_kernel = return_kernel\n",
    "\n",
    "        # extract blur kernel (use an MNIST digit)\n",
    "        self.kernel_dataset = MNIST('./', train=True, download=True,\n",
    "                                    transform=Compose([Lambda(lambda x: np.array(x)),\n",
    "                                                       ToTensor(),\n",
    "                                                       Lambda(lambda x: x / torch.sum(x))]))\n",
    "\n",
    "        kernels = torch.cat([x[0] for (x, _) in zip(self.kernel_dataset, np.arange(self.images.shape[0]))])\n",
    "        kernels = torch.nn.functional.interpolate(kernels[:, None, ...], size=2*(kernel_size,))\n",
    "        kernels = kernels / torch.sum(kernels, dim=(-1, -2), keepdim=True)\n",
    "        self.kernel = kernels[[0]].repeat(kernels.shape[0], 1, 1, 1)\n",
    "\n",
    "        # blur the images\n",
    "        H = psf2otf(self.kernel, self.images.shape)\n",
    "        self.blurred_images = ifft2(fft2(self.images) * H).real\n",
    "        self.blurred_patches = self.patchify(self.blurred_images, patch_size)\n",
    "\n",
    "        # save which blur kernel is used for each image\n",
    "        self.patch_kernel = self.kernel.repeat(1, len(self.blurred_patches) // len(self.images), 1, 1)\n",
    "        self.patch_kernel = self.patch_kernel.view(-1, *self.kernel.shape[-2:])\n",
    "\n",
    "        # reshape kernel\n",
    "        self.kernel = self.kernel.squeeze()\n",
    "\n",
    "    def get_kernel(self, kernel_size, sigma):\n",
    "        kernel = self.gaussian(kernel_size, sigma)\n",
    "        kernel_2d = torch.matmul(kernel.unsqueeze(-1), kernel.unsqueeze(-1).t())\n",
    "        return kernel_2d\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        out = [self.blurred_images[idx][None, ...].to(device),\n",
    "               self.images[idx][None, ...].to(device)]\n",
    "        if self.return_kernel:\n",
    "            out.append(self.kernel[[idx]].to(device))\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25b7dd96",
   "metadata": {
    "id": "25b7dd96"
   },
   "outputs": [],
   "source": [
    "def img_to_numpy(x):\n",
    "    return np.clip(x.detach().cpu().numpy().squeeze().transpose(1, 2, 0), 0, 1)\n",
    "\n",
    "\n",
    "def psf2otf(psf, shape):\n",
    "    inshape = psf.shape\n",
    "    psf = torch.nn.functional.pad(psf, (0, shape[-1] - inshape[-1], 0, shape[-2] - inshape[-2], 0, 0))\n",
    "\n",
    "    # Circularly shift OTF so that the 'center' of the PSF is [0,0] element of the array\n",
    "    psf = torch.roll(psf, shifts=(-int(inshape[-1] / 2), -int(inshape[-2] / 2)), dims=(-1, -2))\n",
    "\n",
    "    # Compute the OTF\n",
    "    otf = fft2(psf)\n",
    "\n",
    "    return otf\n",
    "\n",
    "\n",
    "def calc_psnr(x, gt):\n",
    "    out = 10 * np.log10(1 / ((x - gt)**2).mean().item())\n",
    "    return out\n",
    "\n",
    "\n",
    "def wiener_deconv(x, kernel):\n",
    "    snr = 100  # use this SNR parameter for your results\n",
    "    H = psf2otf(kernel, x.shape).to(device)\n",
    "    G = torch.conj(H) * 1/(1/snr + H*torch.conj(H)).to(device)\n",
    "    return ifft2(fft2(x) * G).real\n",
    "\n",
    "\n",
    "def load_models():\n",
    "    model_deblur_denoise = Unet().to(device)\n",
    "    model_deblur_denoise.load_state_dict(torch.load('utils/models/pretrained/deblur_denoise.pth', map_location=device))\n",
    "\n",
    "    model_denoise = Unet().to(device)\n",
    "    model_denoise.load_state_dict(torch.load('utils/models/pretrained/denoise.pth', map_location=device))\n",
    "\n",
    "    return model_deblur_denoise, model_denoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "TQ0mANFURGYa",
   "metadata": {
    "id": "TQ0mANFURGYa"
   },
   "outputs": [],
   "source": [
    "def fspecial_gaussian_2d(size, sigma):\n",
    "    kernel = np.zeros(tuple(size))\n",
    "    kernel[size[0]//2, size[1]//2] = 1\n",
    "    kernel = gaussian(kernel, sigma)\n",
    "    return kernel/np.sum(kernel)\n",
    "\n",
    "def bilateral2d(img, radius, sigma, sigmaIntensity):\n",
    "    pad = radius\n",
    "    # Initialize filtered image to 0\n",
    "    out = np.zeros_like(img)\n",
    "\n",
    "    # Pad image to reduce boundary artifacts\n",
    "    imgPad = np.pad(img, pad)\n",
    "\n",
    "    # Smoothing kernel, gaussian with standard deviation sigma\n",
    "    # and size (2*radius+1, 2*radius+1)\n",
    "    filtSize = (2*radius + 1, 2*radius + 1)\n",
    "    spatialKernel = fspecial_gaussian_2d(filtSize, sigma)\n",
    "    for x in range(img.shape[0]):\n",
    "        for y in range(img.shape[1]):\n",
    "            I = imgPad[x+pad][y+pad]\n",
    "\n",
    "            # create a window\n",
    "            window = np.zeros((2*radius + 1, 2*radius + 1))\n",
    "            for i in range(-radius, radius+1):\n",
    "                for j in range(-radius, radius+1):\n",
    "                    if (0 <= x+i+pad < img.shape[0] and 0 <= y+j+pad < img.shape[1]):\n",
    "                        window[radius+i][radius+j] = imgPad[x+i+pad][y+j+pad]\n",
    "\n",
    "            intensity = np.exp((-np.square(window-I))/(2*sigmaIntensity**2))\n",
    "\n",
    "            Wp = np.sum(intensity*spatialKernel)\n",
    "            # Go over a window of size (2*radius + 1) around the current pixel,\n",
    "            # compute weights, sum the weighted intensity.\n",
    "            # Don't forget to normalize by the sum of the weights used.\n",
    "\n",
    "            out[x][y] = np.sum(window*intensity*spatialKernel)/Wp\n",
    "    return out\n",
    "\n",
    "def inbounds(img, y, x):\n",
    "    return 0 <= y and y < img.shape[0] and \\\n",
    "           0 <= x and x < img.shape[1]\n",
    "\n",
    "def comparePatches(patch1, patch2, kernel, sigma):\n",
    "    return np.exp(-np.sum(kernel*(patch1 - patch2) ** 2)/(2*sigma**2))\n",
    "\n",
    "def nonlocalmeans(img, searchWindowRadius, averageFilterRadius, sigma, nlmSigma):\n",
    "    # Initialize output to 0\n",
    "    out = np.zeros_like(img)\n",
    "    # Pad image to reduce boundary artifacts\n",
    "    pad = max(averageFilterRadius, searchWindowRadius)\n",
    "    imgPad = np.pad(img, pad)\n",
    "    imgPad = imgPad[..., pad:-pad] # Don't pad third channel\n",
    "\n",
    "    # Smoothing kernel\n",
    "    filtSize = (2*averageFilterRadius + 1, 2*averageFilterRadius + 1)\n",
    "    kernel = fspecial_gaussian_2d(filtSize, sigma)\n",
    "    # Add third axis for broadcasting\n",
    "    kernel = kernel[:, :, np.newaxis]\n",
    "    for y in range(img.shape[0]):\n",
    "        for x in range(img.shape[1]):\n",
    "            # patch for the pixel i\n",
    "            pixel_i = imgPad[y+pad][x+pad]\n",
    "            centerPatch = imgPad[y+pad-averageFilterRadius:y+pad+averageFilterRadius+1,\n",
    "                                 x+pad-averageFilterRadius:x+pad+averageFilterRadius+1,\n",
    "                                 :]\n",
    "            Z = np.zeros((2*searchWindowRadius+1, 2*searchWindowRadius+1, 1))\n",
    "            # Go over a window around the current pixel, compute weights\n",
    "            # based on difference of patches, sum the weighted intensity\n",
    "            # Hint: Do NOT include the patches centered at the current pixel\n",
    "            # in this loop, it will throw off the weights\n",
    "            weights = np.zeros((2*searchWindowRadius+1, 2*searchWindowRadius+1, 1))\n",
    "\n",
    "            # This makes it a bit better: Add current pixel as well with max weight\n",
    "            # computed from all other neighborhoods.\n",
    "            max_weight = 0\n",
    "\n",
    "            # creates a window of size: searchWindowRadius\n",
    "            window = imgPad[y+pad-searchWindowRadius:y+pad+searchWindowRadius+1, \n",
    "                            x+pad-searchWindowRadius:x+pad+searchWindowRadius+1,\n",
    "                            :]\n",
    "\n",
    "            # go through OTHER pixels (pixel j) in the window\n",
    "            for b in range(-searchWindowRadius, searchWindowRadius+1):\n",
    "                for a in range(-searchWindowRadius, searchWindowRadius+1):\n",
    "                    if (b != 0 and a != 0):\n",
    "                        pixel_j = imgPad[y+b+pad][x+a+pad]\n",
    "                        # create a patch for pixel j, if some pixels (say pixel(m,n)) in the patch are outside\n",
    "                        # the window, then set them to 0\n",
    "\n",
    "                        # check boundary\n",
    "                        if inbounds(imgPad, y+b+pad-averageFilterRadius, \n",
    "                            x+a+pad-averageFilterRadius) and inbounds(imgPad, y+b+pad+averageFilterRadius, \n",
    "                            x+a+pad+averageFilterRadius):\n",
    "                            patch_j = imgPad[y+b+pad-averageFilterRadius:y+b+pad+averageFilterRadius+1, \n",
    "                                             x+a+pad-averageFilterRadius:x+a+pad+averageFilterRadius+1,\n",
    "                                             :]\n",
    "                        else:\n",
    "                            patch_j = np.zeros_like(centerPatch)\n",
    "                            for m in range(-averageFilterRadius,averageFilterRadius+1):\n",
    "                                for n in range(-averageFilterRadius,averageFilterRadius+1):\n",
    "                                    pixel_in_patch_y = y+b+pad+m\n",
    "                                    pixel_in_patch_x = x+a+pad+n\n",
    "                                    if inbounds(imgPad, pixel_in_patch_y, pixel_in_patch_x):\n",
    "                                        patch_j[m+averageFilterRadius][n+averageFilterRadius] = imgPad[y+b+pad+m][x+a+pad+n]\n",
    "\n",
    "\n",
    "\n",
    "                        weights[b+searchWindowRadius][a+searchWindowRadius] = comparePatches(centerPatch, patch_j, kernel, nlmSigma)\n",
    "                        Z[b+searchWindowRadius][a+searchWindowRadius] = comparePatches(centerPatch, patch_j, kernel, nlmSigma)*pixel_j\n",
    "            out[y, x, :] = np.sum(Z)/np.sum(weights)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4cc1afeb",
   "metadata": {
    "id": "4cc1afeb"
   },
   "outputs": [],
   "source": [
    "def evaluate_model():\n",
    "\n",
    "    # create the dataset\n",
    "    dataset = BlurredBSDS300Dataset(split='test')\n",
    "\n",
    "    # load the models\n",
    "    model_deblur_denoise, model_denoise = load_models()\n",
    "\n",
    "    # put into evaluation mode\n",
    "    model_deblur_denoise.eval()\n",
    "    model_denoise.eval()\n",
    "    \n",
    "    PSNRs = []\n",
    "\n",
    "    for sigma in [0.01, 0.02, 0.05]:\n",
    "\n",
    "        filtSize = 2*sigma + 1\n",
    "        \n",
    "        psnr_m1 = []\n",
    "        psnr_m2 = []\n",
    "        psnr_m3 = []\n",
    "        psnr_m4 = []\n",
    "        psnr_m5 = []\n",
    "        psnr_m6 = []\n",
    "        psnr_m7 = []\n",
    "        \n",
    "        index = 0\n",
    "\n",
    "        for image, gt, kernel in dataset:\n",
    "\n",
    "            ################################################################################\n",
    "            # TODO: Your code goes here!\n",
    "            ################################################################################\n",
    "\n",
    "            # add noise to the image\n",
    "            \n",
    "            image = image + sigma * torch.tensor(np.random.randn(*image.shape)).to(device)\n",
    "\n",
    "            # apply each method (wiener deconvolution and the two networks)\n",
    "            \n",
    "            # Method 1: Wiener deconvolution\n",
    "            \n",
    "            image_deconv = wiener_deconv(image, kernel)\n",
    "            \n",
    "            psnr_m1.append(calc_psnr(image_deconv, gt))\n",
    "            \n",
    "            # Method 2: Neural Network for deconvolution + denoising\n",
    "            \n",
    "            image_neural = model_deblur_denoise(image.to(dtype=torch.float))\n",
    "            \n",
    "            psnr_m2.append(calc_psnr(image_neural, gt))\n",
    "            \n",
    "            # Method 3: Wiener deconvolution + Neural Network denoising\n",
    "            \n",
    "            image_deconv_neural = model_denoise(image_deconv.to(dtype=torch.float))\n",
    "            \n",
    "            psnr_m3.append(calc_psnr(image_deconv_neural, gt))\n",
    "\n",
    "            # Method 4: Gaussian Filter\n",
    "            \n",
    "            np_img = img_to_numpy(image)\n",
    "            image_Gaussian_filter = np.zeros_like(np_img)\n",
    "            for channel in [0, 1, 2]:\n",
    "                image_Gaussian_filter[:,:, channel] = gaussian(np_img[:,:, channel], sigma = 1)\n",
    "            psnr_m4.append(calc_psnr(image_Gaussian_filter, img_to_numpy(gt)))\n",
    "\n",
    "            # Method 5: Median Filter\n",
    "            \n",
    "            np_img = img_to_numpy(image)\n",
    "            image_Median_filter = np.zeros_like(np_img)\n",
    "            for channel in [0, 1, 2]:\n",
    "                image_Median_filter[:,:, channel] = median_filter(np_img[:,:, channel], size=3)\n",
    "            psnr_m5.append(calc_psnr(image_Median_filter, img_to_numpy(gt)))\n",
    "\n",
    "            # Method 6: Bilateral\n",
    "            sigmaIntensity = 0.25\n",
    "            bilateral = np.zeros_like(np_img)\n",
    "            for channel in [0, 1, 2]:\n",
    "                bilateral[:,:, channel] = bilateral2d(np_img[:,:, channel],\n",
    "                                              radius=1,\n",
    "                                              sigma=1,\n",
    "                                              sigmaIntensity=sigmaIntensity)\n",
    "            psnr_m6.append(calc_psnr(bilateral, img_to_numpy(gt)))\n",
    "            \n",
    "            # Method 7: Non Local Mean\n",
    "            nlmSigma = 0.1  # Feel free to modify\n",
    "            searchWindowRadius = 5\n",
    "            averageFilterRadius = 1\n",
    "            nlm = np.zeros_like(np_img)\n",
    "            # for channel in [0,1,2]:\n",
    "              # nlm[...,channel:channel+1] = nonlocalmeans(np_img[..., channel:channel+1],searchWindowRadius,averageFilterRadius,1,nlmSigma)\n",
    "            psnr_m7.append(calc_psnr(nlm, img_to_numpy(gt)))\n",
    "\n",
    "            filename = 'data/noisy_images/'\n",
    "            skimage.io.imsave(filename + str(index) + '_sigma=' + str(sigma) + '_gt.png', (img_to_numpy(gt)*255).astype(np.uint8))\n",
    "            skimage.io.imsave(filename + str(index) + '_sigma=' + str(sigma) + '_noisy.png', (img_to_numpy(image)*255).astype(np.uint8))\n",
    "            skimage.io.imsave(filename + str(index) + '_sigma=' + str(sigma) + '_deconv.png', (img_to_numpy(image_deconv)*255).astype(np.uint8))\n",
    "            skimage.io.imsave(filename + str(index) + '_sigma=' + str(sigma) + '_neural.png', (img_to_numpy(image_neural)*255).astype(np.uint8))\n",
    "            skimage.io.imsave(filename + str(index) + '_sigma=' + str(sigma) + '_deconv_neural.png', (img_to_numpy(image_deconv_neural)*255).astype(np.uint8))\n",
    "            skimage.io.imsave(filename + str(index) + '_sigma=' + str(sigma) + '_Gaussian_filt.png', (image_Gaussian_filter*255).astype(np.uint8))\n",
    "            skimage.io.imsave(filename + str(index) + '_sigma=' + str(sigma) + '_Median_filt.png', (image_Median_filter*255).astype(np.uint8))\n",
    "            skimage.io.imsave(filename + str(index) + '_sigma=' + str(sigma) + '_bilateral.png', (bilateral*255).astype(np.uint8))\n",
    "            # skimage.io.imsave(filename + str(index) + '_sigma=' + str(sigma) + '_nlm.png', (nlm*255).astype(np.uint8))\n",
    "            \n",
    "            index = index + 1\n",
    "    \n",
    "        PSNRs.append(statistics.mean(psnr_m1))\n",
    "        PSNRs.append(statistics.mean(psnr_m2))\n",
    "        PSNRs.append(statistics.mean(psnr_m3))\n",
    "        PSNRs.append(statistics.mean(psnr_m4))\n",
    "        PSNRs.append(statistics.mean(psnr_m5))\n",
    "        PSNRs.append(statistics.mean(psnr_m6))\n",
    "        PSNRs.append(statistics.mean(psnr_m7))\n",
    "  \n",
    "    print(PSNRs)\n",
    "\n",
    "            # save the psnrs\n",
    "\n",
    "            # save out sample images to include in your writeup\n",
    "\n",
    "            # HINT: use the calc_psnr function to calculate the PSNR, and use the\n",
    "            # wiener_deconv function to perform wiener deconvolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "97258c21",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "97258c21",
    "outputId": "4de92900-d766-44c9-db0c-a6ef96a940d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23.047227985993118, 26.883143406554414, 29.257634762978444, 27.940247316804285, 28.052817605755013, 27.732639326304803, 6.981957042618609, 15.18032631299592, 18.95537563689762, 21.053419372250413, 27.39368349860837, 26.947414538295522, 26.886025416233508, 6.981957042618609]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    evaluate_model()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python3.7 (Comp Img)",
   "language": "python",
   "name": "compimg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
